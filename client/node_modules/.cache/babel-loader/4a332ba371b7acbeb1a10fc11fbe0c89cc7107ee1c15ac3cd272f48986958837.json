{"ast":null,"code":"\"use strict\";\n\nvar _objectSpread = require(\"/home/salman/Documents/GitHub/FakeShop/node_modules/@babel/runtime/helpers/objectSpread2.js\").default;\nvar _regeneratorRuntime = require(\"/home/salman/Documents/GitHub/FakeShop/node_modules/@babel/runtime/helpers/regeneratorRuntime.js\").default;\nvar _asyncToGenerator = require(\"/home/salman/Documents/GitHub/FakeShop/node_modules/@babel/runtime/helpers/asyncToGenerator.js\").default;\nvar _classCallCheck = require(\"/home/salman/Documents/GitHub/FakeShop/node_modules/@babel/runtime/helpers/classCallCheck.js\").default;\nvar _createClass = require(\"/home/salman/Documents/GitHub/FakeShop/node_modules/@babel/runtime/helpers/createClass.js\").default;\nvar _assertThisInitialized = require(\"/home/salman/Documents/GitHub/FakeShop/node_modules/@babel/runtime/helpers/assertThisInitialized.js\").default;\nvar _inherits = require(\"/home/salman/Documents/GitHub/FakeShop/node_modules/@babel/runtime/helpers/inherits.js\").default;\nvar _createSuper = require(\"/home/salman/Documents/GitHub/FakeShop/node_modules/@babel/runtime/helpers/createSuper.js\").default;\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.GridFSBucketWriteStream = void 0;\nvar stream_1 = require(\"stream\");\nvar bson_1 = require(\"../bson\");\nvar error_1 = require(\"../error\");\nvar write_concern_1 = require(\"./../write_concern\");\n/**\n * A writable stream that enables you to write buffers to GridFS.\n *\n * Do not instantiate this class directly. Use `openUploadStream()` instead.\n * @public\n */\nvar GridFSBucketWriteStream = /*#__PURE__*/function (_stream_1$Writable) {\n  _inherits(GridFSBucketWriteStream, _stream_1$Writable);\n  var _super = _createSuper(GridFSBucketWriteStream);\n  /**\n   * @param bucket - Handle for this stream's corresponding bucket\n   * @param filename - The value of the 'filename' key in the files doc\n   * @param options - Optional settings.\n   * @internal\n   */\n  function GridFSBucketWriteStream(bucket, filename, options) {\n    var _options;\n    var _this;\n    _classCallCheck(this, GridFSBucketWriteStream);\n    _this = _super.call(this);\n    options = (_options = options) !== null && _options !== void 0 ? _options : {};\n    _this.bucket = bucket;\n    _this.chunks = bucket.s._chunksCollection;\n    _this.filename = filename;\n    _this.files = bucket.s._filesCollection;\n    _this.options = options;\n    _this.writeConcern = write_concern_1.WriteConcern.fromOptions(options) || bucket.s.options.writeConcern;\n    // Signals the write is all done\n    _this.done = false;\n    _this.id = options.id ? options.id : new bson_1.ObjectId();\n    // properly inherit the default chunksize from parent\n    _this.chunkSizeBytes = options.chunkSizeBytes || _this.bucket.s.options.chunkSizeBytes;\n    _this.bufToStore = Buffer.alloc(_this.chunkSizeBytes);\n    _this.length = 0;\n    _this.n = 0;\n    _this.pos = 0;\n    _this.state = {\n      streamEnd: false,\n      outstandingRequests: 0,\n      errored: false,\n      aborted: false\n    };\n    if (!_this.bucket.s.calledOpenUploadStream) {\n      _this.bucket.s.calledOpenUploadStream = true;\n      checkIndexes(_assertThisInitialized(_this)).then(function () {\n        _this.bucket.s.checkedIndexes = true;\n        _this.bucket.emit('index');\n      }, function () {\n        return null;\n      });\n    }\n    return _this;\n  }\n  _createClass(GridFSBucketWriteStream, [{\n    key: \"write\",\n    value: function write(chunk, encodingOrCallback, callback) {\n      var _this2 = this;\n      var encoding = typeof encodingOrCallback === 'function' ? undefined : encodingOrCallback;\n      callback = typeof encodingOrCallback === 'function' ? encodingOrCallback : callback;\n      return waitForIndexes(this, function () {\n        return doWrite(_this2, chunk, encoding, callback);\n      });\n    }\n    /**\n     * Places this write stream into an aborted state (all future writes fail)\n     * and deletes all chunks that have already been written.\n     */\n  }, {\n    key: \"abort\",\n    value: function () {\n      var _abort = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee() {\n        return _regeneratorRuntime().wrap(function _callee$(_context) {\n          while (1) switch (_context.prev = _context.next) {\n            case 0:\n              if (!this.state.streamEnd) {\n                _context.next = 2;\n                break;\n              }\n              throw new error_1.MongoAPIError('Cannot abort a stream that has already completed');\n            case 2:\n              if (!this.state.aborted) {\n                _context.next = 4;\n                break;\n              }\n              throw new error_1.MongoAPIError('Cannot call abort() on a stream twice');\n            case 4:\n              this.state.aborted = true;\n              _context.next = 7;\n              return this.chunks.deleteMany({\n                files_id: this.id\n              });\n            case 7:\n            case \"end\":\n              return _context.stop();\n          }\n        }, _callee, this);\n      }));\n      function abort() {\n        return _abort.apply(this, arguments);\n      }\n      return abort;\n    }()\n  }, {\n    key: \"end\",\n    value: function end(chunkOrCallback, encodingOrCallback, callback) {\n      var _this3 = this;\n      var chunk = typeof chunkOrCallback === 'function' ? undefined : chunkOrCallback;\n      var encoding = typeof encodingOrCallback === 'function' ? undefined : encodingOrCallback;\n      callback = typeof chunkOrCallback === 'function' ? chunkOrCallback : typeof encodingOrCallback === 'function' ? encodingOrCallback : callback;\n      if (this.state.streamEnd || checkAborted(this, callback)) return this;\n      this.state.streamEnd = true;\n      if (callback) {\n        this.once(GridFSBucketWriteStream.FINISH, function (result) {\n          if (callback) callback(undefined, result);\n        });\n      }\n      if (!chunk) {\n        waitForIndexes(this, function () {\n          return !!writeRemnant(_this3);\n        });\n        return this;\n      }\n      this.write(chunk, encoding, function () {\n        writeRemnant(_this3);\n      });\n      return this;\n    }\n  }]);\n  return GridFSBucketWriteStream;\n}(stream_1.Writable);\n/** @event */\nGridFSBucketWriteStream.CLOSE = 'close';\n/** @event */\nGridFSBucketWriteStream.ERROR = 'error';\n/**\n * `end()` was called and the write stream successfully wrote the file metadata and all the chunks to MongoDB.\n * @event\n */\nGridFSBucketWriteStream.FINISH = 'finish';\nexports.GridFSBucketWriteStream = GridFSBucketWriteStream;\nfunction __handleError(stream, error, callback) {\n  if (stream.state.errored) {\n    return;\n  }\n  stream.state.errored = true;\n  if (callback) {\n    return callback(error);\n  }\n  stream.emit(GridFSBucketWriteStream.ERROR, error);\n}\nfunction createChunkDoc(filesId, n, data) {\n  return {\n    _id: new bson_1.ObjectId(),\n    files_id: filesId,\n    n: n,\n    data: data\n  };\n}\nfunction checkChunksIndex(_x) {\n  return _checkChunksIndex.apply(this, arguments);\n}\nfunction _checkChunksIndex() {\n  _checkChunksIndex = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee2(stream) {\n    var index, indexes, hasChunksIndex;\n    return _regeneratorRuntime().wrap(function _callee2$(_context2) {\n      while (1) switch (_context2.prev = _context2.next) {\n        case 0:\n          index = {\n            files_id: 1,\n            n: 1\n          };\n          _context2.prev = 1;\n          _context2.next = 4;\n          return stream.chunks.listIndexes().toArray();\n        case 4:\n          indexes = _context2.sent;\n          _context2.next = 14;\n          break;\n        case 7:\n          _context2.prev = 7;\n          _context2.t0 = _context2[\"catch\"](1);\n          if (!(_context2.t0 instanceof error_1.MongoError && _context2.t0.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound)) {\n            _context2.next = 13;\n            break;\n          }\n          indexes = [];\n          _context2.next = 14;\n          break;\n        case 13:\n          throw _context2.t0;\n        case 14:\n          hasChunksIndex = !!indexes.find(function (index) {\n            var keys = Object.keys(index.key);\n            if (keys.length === 2 && index.key.files_id === 1 && index.key.n === 1) {\n              return true;\n            }\n            return false;\n          });\n          if (hasChunksIndex) {\n            _context2.next = 18;\n            break;\n          }\n          _context2.next = 18;\n          return stream.chunks.createIndex(index, _objectSpread(_objectSpread({}, stream.writeConcern), {}, {\n            background: true,\n            unique: true\n          }));\n        case 18:\n        case \"end\":\n          return _context2.stop();\n      }\n    }, _callee2, null, [[1, 7]]);\n  }));\n  return _checkChunksIndex.apply(this, arguments);\n}\nfunction checkDone(stream, callback) {\n  if (stream.done) return true;\n  if (stream.state.streamEnd && stream.state.outstandingRequests === 0 && !stream.state.errored) {\n    // Set done so we do not trigger duplicate createFilesDoc\n    stream.done = true;\n    // Create a new files doc\n    var filesDoc = createFilesDoc(stream.id, stream.length, stream.chunkSizeBytes, stream.filename, stream.options.contentType, stream.options.aliases, stream.options.metadata);\n    if (checkAborted(stream, callback)) {\n      return false;\n    }\n    stream.files.insertOne(filesDoc, {\n      writeConcern: stream.writeConcern\n    }).then(function () {\n      stream.emit(GridFSBucketWriteStream.FINISH, filesDoc);\n      stream.emit(GridFSBucketWriteStream.CLOSE);\n    }, function (error) {\n      return __handleError(stream, error, callback);\n    });\n    return true;\n  }\n  return false;\n}\nfunction checkIndexes(_x2) {\n  return _checkIndexes.apply(this, arguments);\n}\nfunction _checkIndexes() {\n  _checkIndexes = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime().mark(function _callee3(stream) {\n    var doc, index, indexes, hasFileIndex;\n    return _regeneratorRuntime().wrap(function _callee3$(_context3) {\n      while (1) switch (_context3.prev = _context3.next) {\n        case 0:\n          _context3.next = 2;\n          return stream.files.findOne({}, {\n            projection: {\n              _id: 1\n            }\n          });\n        case 2:\n          doc = _context3.sent;\n          if (!(doc != null)) {\n            _context3.next = 5;\n            break;\n          }\n          return _context3.abrupt(\"return\");\n        case 5:\n          index = {\n            filename: 1,\n            uploadDate: 1\n          };\n          _context3.prev = 6;\n          _context3.next = 9;\n          return stream.files.listIndexes().toArray();\n        case 9:\n          indexes = _context3.sent;\n          _context3.next = 19;\n          break;\n        case 12:\n          _context3.prev = 12;\n          _context3.t0 = _context3[\"catch\"](6);\n          if (!(_context3.t0 instanceof error_1.MongoError && _context3.t0.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound)) {\n            _context3.next = 18;\n            break;\n          }\n          indexes = [];\n          _context3.next = 19;\n          break;\n        case 18:\n          throw _context3.t0;\n        case 19:\n          hasFileIndex = !!indexes.find(function (index) {\n            var keys = Object.keys(index.key);\n            if (keys.length === 2 && index.key.filename === 1 && index.key.uploadDate === 1) {\n              return true;\n            }\n            return false;\n          });\n          if (hasFileIndex) {\n            _context3.next = 23;\n            break;\n          }\n          _context3.next = 23;\n          return stream.files.createIndex(index, {\n            background: false\n          });\n        case 23:\n          _context3.next = 25;\n          return checkChunksIndex(stream);\n        case 25:\n        case \"end\":\n          return _context3.stop();\n      }\n    }, _callee3, null, [[6, 12]]);\n  }));\n  return _checkIndexes.apply(this, arguments);\n}\nfunction createFilesDoc(_id, length, chunkSize, filename, contentType, aliases, metadata) {\n  var ret = {\n    _id: _id,\n    length: length,\n    chunkSize: chunkSize,\n    uploadDate: new Date(),\n    filename: filename\n  };\n  if (contentType) {\n    ret.contentType = contentType;\n  }\n  if (aliases) {\n    ret.aliases = aliases;\n  }\n  if (metadata) {\n    ret.metadata = metadata;\n  }\n  return ret;\n}\nfunction doWrite(stream, chunk, encoding, callback) {\n  if (checkAborted(stream, callback)) {\n    return false;\n  }\n  var inputBuf = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk, encoding);\n  stream.length += inputBuf.length;\n  // Input is small enough to fit in our buffer\n  if (stream.pos + inputBuf.length < stream.chunkSizeBytes) {\n    inputBuf.copy(stream.bufToStore, stream.pos);\n    stream.pos += inputBuf.length;\n    callback && callback();\n    // Note that we reverse the typical semantics of write's return value\n    // to be compatible with node's `.pipe()` function.\n    // True means client can keep writing.\n    return true;\n  }\n  // Otherwise, buffer is too big for current chunk, so we need to flush\n  // to MongoDB.\n  var inputBufRemaining = inputBuf.length;\n  var spaceRemaining = stream.chunkSizeBytes - stream.pos;\n  var numToCopy = Math.min(spaceRemaining, inputBuf.length);\n  var outstandingRequests = 0;\n  var _loop = function _loop() {\n    var inputBufPos = inputBuf.length - inputBufRemaining;\n    inputBuf.copy(stream.bufToStore, stream.pos, inputBufPos, inputBufPos + numToCopy);\n    stream.pos += numToCopy;\n    spaceRemaining -= numToCopy;\n    var doc;\n    if (spaceRemaining === 0) {\n      doc = createChunkDoc(stream.id, stream.n, Buffer.from(stream.bufToStore));\n      ++stream.state.outstandingRequests;\n      ++outstandingRequests;\n      if (checkAborted(stream, callback)) {\n        return {\n          v: false\n        };\n      }\n      stream.chunks.insertOne(doc, {\n        writeConcern: stream.writeConcern\n      }).then(function () {\n        --stream.state.outstandingRequests;\n        --outstandingRequests;\n        if (!outstandingRequests) {\n          stream.emit('drain', doc);\n          callback && callback();\n          checkDone(stream);\n        }\n      }, function (error) {\n        return __handleError(stream, error);\n      });\n      spaceRemaining = stream.chunkSizeBytes;\n      stream.pos = 0;\n      ++stream.n;\n    }\n    inputBufRemaining -= numToCopy;\n    numToCopy = Math.min(spaceRemaining, inputBufRemaining);\n  };\n  while (inputBufRemaining > 0) {\n    var _ret = _loop();\n    if (typeof _ret === \"object\") return _ret.v;\n  }\n  // Note that we reverse the typical semantics of write's return value\n  // to be compatible with node's `.pipe()` function.\n  // False means the client should wait for the 'drain' event.\n  return false;\n}\nfunction waitForIndexes(stream, callback) {\n  if (stream.bucket.s.checkedIndexes) {\n    return callback(false);\n  }\n  stream.bucket.once('index', function () {\n    callback(true);\n  });\n  return true;\n}\nfunction writeRemnant(stream, callback) {\n  // Buffer is empty, so don't bother to insert\n  if (stream.pos === 0) {\n    return checkDone(stream, callback);\n  }\n  ++stream.state.outstandingRequests;\n  // Create a new buffer to make sure the buffer isn't bigger than it needs\n  // to be.\n  var remnant = Buffer.alloc(stream.pos);\n  stream.bufToStore.copy(remnant, 0, 0, stream.pos);\n  var doc = createChunkDoc(stream.id, stream.n, remnant);\n  // If the stream was aborted, do not write remnant\n  if (checkAborted(stream, callback)) {\n    return false;\n  }\n  stream.chunks.insertOne(doc, {\n    writeConcern: stream.writeConcern\n  }).then(function () {\n    --stream.state.outstandingRequests;\n    checkDone(stream);\n  }, function (error) {\n    return __handleError(stream, error);\n  });\n  return true;\n}\nfunction checkAborted(stream, callback) {\n  if (stream.state.aborted) {\n    if (typeof callback === 'function') {\n      // TODO(NODE-3485): Replace with MongoGridFSStreamClosedError\n      callback(new error_1.MongoAPIError('Stream has been aborted'));\n    }\n    return true;\n  }\n  return false;\n}","map":{"version":3,"names":["stream_1","require","bson_1","error_1","write_concern_1","GridFSBucketWriteStream","_stream_1$Writable","_inherits","_super","_createSuper","bucket","filename","options","_options","_this","_classCallCheck","call","chunks","s","_chunksCollection","files","_filesCollection","writeConcern","WriteConcern","fromOptions","done","id","ObjectId","chunkSizeBytes","bufToStore","Buffer","alloc","length","n","pos","state","streamEnd","outstandingRequests","errored","aborted","calledOpenUploadStream","checkIndexes","_assertThisInitialized","then","checkedIndexes","emit","_createClass","key","value","write","chunk","encodingOrCallback","callback","_this2","encoding","undefined","waitForIndexes","doWrite","_abort","_asyncToGenerator","_regeneratorRuntime","mark","_callee","wrap","_callee$","_context","prev","next","MongoAPIError","deleteMany","files_id","stop","abort","apply","arguments","end","chunkOrCallback","_this3","checkAborted","once","FINISH","result","writeRemnant","Writable","CLOSE","ERROR","exports","__handleError","stream","error","createChunkDoc","filesId","data","_id","checkChunksIndex","_x","_checkChunksIndex","_callee2","index","indexes","hasChunksIndex","_callee2$","_context2","listIndexes","toArray","sent","t0","MongoError","code","MONGODB_ERROR_CODES","NamespaceNotFound","find","keys","Object","createIndex","_objectSpread","background","unique","checkDone","filesDoc","createFilesDoc","contentType","aliases","metadata","insertOne","_x2","_checkIndexes","_callee3","doc","hasFileIndex","_callee3$","_context3","findOne","projection","abrupt","uploadDate","chunkSize","ret","Date","inputBuf","isBuffer","from","copy","inputBufRemaining","spaceRemaining","numToCopy","Math","min","_loop","inputBufPos","v","_ret","remnant"],"sources":["/home/salman/Documents/GitHub/FakeShop/node_modules/mongodb/src/gridfs/upload.ts"],"sourcesContent":["import { Writable } from 'stream';\n\nimport type { Document } from '../bson';\nimport { ObjectId } from '../bson';\nimport type { Collection } from '../collection';\nimport { type AnyError, MongoAPIError, MONGODB_ERROR_CODES, MongoError } from '../error';\nimport type { Callback } from '../utils';\nimport type { WriteConcernOptions } from '../write_concern';\nimport { WriteConcern } from './../write_concern';\nimport type { GridFSFile } from './download';\nimport type { GridFSBucket } from './index';\n\n/** @public */\nexport interface GridFSChunk {\n  _id: ObjectId;\n  files_id: ObjectId;\n  n: number;\n  data: Buffer | Uint8Array;\n}\n\n/** @public */\nexport interface GridFSBucketWriteStreamOptions extends WriteConcernOptions {\n  /** Overwrite this bucket's chunkSizeBytes for this file */\n  chunkSizeBytes?: number;\n  /** Custom file id for the GridFS file. */\n  id?: ObjectId;\n  /** Object to store in the file document's `metadata` field */\n  metadata?: Document;\n  /** String to store in the file document's `contentType` field */\n  contentType?: string;\n  /** Array of strings to store in the file document's `aliases` field */\n  aliases?: string[];\n}\n\n/**\n * A writable stream that enables you to write buffers to GridFS.\n *\n * Do not instantiate this class directly. Use `openUploadStream()` instead.\n * @public\n */\nexport class GridFSBucketWriteStream extends Writable implements NodeJS.WritableStream {\n  bucket: GridFSBucket;\n  chunks: Collection<GridFSChunk>;\n  filename: string;\n  files: Collection<GridFSFile>;\n  options: GridFSBucketWriteStreamOptions;\n  done: boolean;\n  id: ObjectId;\n  chunkSizeBytes: number;\n  bufToStore: Buffer;\n  length: number;\n  n: number;\n  pos: number;\n  state: {\n    streamEnd: boolean;\n    outstandingRequests: number;\n    errored: boolean;\n    aborted: boolean;\n  };\n  writeConcern?: WriteConcern;\n\n  /** @event */\n  static readonly CLOSE = 'close';\n  /** @event */\n  static readonly ERROR = 'error';\n  /**\n   * `end()` was called and the write stream successfully wrote the file metadata and all the chunks to MongoDB.\n   * @event\n   */\n  static readonly FINISH = 'finish';\n\n  /**\n   * @param bucket - Handle for this stream's corresponding bucket\n   * @param filename - The value of the 'filename' key in the files doc\n   * @param options - Optional settings.\n   * @internal\n   */\n  constructor(bucket: GridFSBucket, filename: string, options?: GridFSBucketWriteStreamOptions) {\n    super();\n\n    options = options ?? {};\n    this.bucket = bucket;\n    this.chunks = bucket.s._chunksCollection;\n    this.filename = filename;\n    this.files = bucket.s._filesCollection;\n    this.options = options;\n    this.writeConcern = WriteConcern.fromOptions(options) || bucket.s.options.writeConcern;\n    // Signals the write is all done\n    this.done = false;\n\n    this.id = options.id ? options.id : new ObjectId();\n    // properly inherit the default chunksize from parent\n    this.chunkSizeBytes = options.chunkSizeBytes || this.bucket.s.options.chunkSizeBytes;\n    this.bufToStore = Buffer.alloc(this.chunkSizeBytes);\n    this.length = 0;\n    this.n = 0;\n    this.pos = 0;\n    this.state = {\n      streamEnd: false,\n      outstandingRequests: 0,\n      errored: false,\n      aborted: false\n    };\n\n    if (!this.bucket.s.calledOpenUploadStream) {\n      this.bucket.s.calledOpenUploadStream = true;\n\n      checkIndexes(this).then(\n        () => {\n          this.bucket.s.checkedIndexes = true;\n          this.bucket.emit('index');\n        },\n        () => null\n      );\n    }\n  }\n\n  /**\n   * Write a buffer to the stream.\n   *\n   * @param chunk - Buffer to write\n   * @param encodingOrCallback - Optional encoding for the buffer\n   * @param callback - Function to call when the chunk was added to the buffer, or if the entire chunk was persisted to MongoDB if this chunk caused a flush.\n   * @returns False if this write required flushing a chunk to MongoDB. True otherwise.\n   */\n  override write(chunk: Buffer | string): boolean;\n  override write(chunk: Buffer | string, callback: Callback<void>): boolean;\n  override write(chunk: Buffer | string, encoding: BufferEncoding | undefined): boolean;\n  override write(\n    chunk: Buffer | string,\n    encoding: BufferEncoding | undefined,\n    callback: Callback<void>\n  ): boolean;\n  override write(\n    chunk: Buffer | string,\n    encodingOrCallback?: Callback<void> | BufferEncoding,\n    callback?: Callback<void>\n  ): boolean {\n    const encoding = typeof encodingOrCallback === 'function' ? undefined : encodingOrCallback;\n    callback = typeof encodingOrCallback === 'function' ? encodingOrCallback : callback;\n    return waitForIndexes(this, () => doWrite(this, chunk, encoding, callback));\n  }\n\n  /**\n   * Places this write stream into an aborted state (all future writes fail)\n   * and deletes all chunks that have already been written.\n   */\n  async abort(): Promise<void> {\n    if (this.state.streamEnd) {\n      // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n      throw new MongoAPIError('Cannot abort a stream that has already completed');\n    }\n\n    if (this.state.aborted) {\n      // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n      throw new MongoAPIError('Cannot call abort() on a stream twice');\n    }\n\n    this.state.aborted = true;\n    await this.chunks.deleteMany({ files_id: this.id });\n  }\n\n  /**\n   * Tells the stream that no more data will be coming in. The stream will\n   * persist the remaining data to MongoDB, write the files document, and\n   * then emit a 'finish' event.\n   *\n   * @param chunk - Buffer to write\n   * @param encoding - Optional encoding for the buffer\n   * @param callback - Function to call when all files and chunks have been persisted to MongoDB\n   */\n  override end(): this;\n  override end(chunk: Buffer): this;\n  override end(callback: Callback<GridFSFile | void>): this;\n  override end(chunk: Buffer, callback: Callback<GridFSFile | void>): this;\n  override end(chunk: Buffer, encoding: BufferEncoding): this;\n  override end(\n    chunk: Buffer,\n    encoding: BufferEncoding | undefined,\n    callback: Callback<GridFSFile | void>\n  ): this;\n  override end(\n    chunkOrCallback?: Buffer | Callback<GridFSFile | void>,\n    encodingOrCallback?: BufferEncoding | Callback<GridFSFile | void>,\n    callback?: Callback<GridFSFile | void>\n  ): this {\n    const chunk = typeof chunkOrCallback === 'function' ? undefined : chunkOrCallback;\n    const encoding = typeof encodingOrCallback === 'function' ? undefined : encodingOrCallback;\n    callback =\n      typeof chunkOrCallback === 'function'\n        ? chunkOrCallback\n        : typeof encodingOrCallback === 'function'\n        ? encodingOrCallback\n        : callback;\n\n    if (this.state.streamEnd || checkAborted(this, callback)) return this;\n\n    this.state.streamEnd = true;\n\n    if (callback) {\n      this.once(GridFSBucketWriteStream.FINISH, (result: GridFSFile) => {\n        if (callback) callback(undefined, result);\n      });\n    }\n\n    if (!chunk) {\n      waitForIndexes(this, () => !!writeRemnant(this));\n      return this;\n    }\n\n    this.write(chunk, encoding, () => {\n      writeRemnant(this);\n    });\n\n    return this;\n  }\n}\n\nfunction __handleError(\n  stream: GridFSBucketWriteStream,\n  error: AnyError,\n  callback?: Callback\n): void {\n  if (stream.state.errored) {\n    return;\n  }\n  stream.state.errored = true;\n  if (callback) {\n    return callback(error);\n  }\n  stream.emit(GridFSBucketWriteStream.ERROR, error);\n}\n\nfunction createChunkDoc(filesId: ObjectId, n: number, data: Buffer): GridFSChunk {\n  return {\n    _id: new ObjectId(),\n    files_id: filesId,\n    n,\n    data\n  };\n}\n\nasync function checkChunksIndex(stream: GridFSBucketWriteStream): Promise<void> {\n  const index = { files_id: 1, n: 1 };\n\n  let indexes;\n  try {\n    indexes = await stream.chunks.listIndexes().toArray();\n  } catch (error) {\n    if (error instanceof MongoError && error.code === MONGODB_ERROR_CODES.NamespaceNotFound) {\n      indexes = [];\n    } else {\n      throw error;\n    }\n  }\n\n  const hasChunksIndex = !!indexes.find(index => {\n    const keys = Object.keys(index.key);\n    if (keys.length === 2 && index.key.files_id === 1 && index.key.n === 1) {\n      return true;\n    }\n    return false;\n  });\n\n  if (!hasChunksIndex) {\n    await stream.chunks.createIndex(index, {\n      ...stream.writeConcern,\n      background: true,\n      unique: true\n    });\n  }\n}\n\nfunction checkDone(stream: GridFSBucketWriteStream, callback?: Callback): boolean {\n  if (stream.done) return true;\n  if (stream.state.streamEnd && stream.state.outstandingRequests === 0 && !stream.state.errored) {\n    // Set done so we do not trigger duplicate createFilesDoc\n    stream.done = true;\n    // Create a new files doc\n    const filesDoc = createFilesDoc(\n      stream.id,\n      stream.length,\n      stream.chunkSizeBytes,\n      stream.filename,\n      stream.options.contentType,\n      stream.options.aliases,\n      stream.options.metadata\n    );\n\n    if (checkAborted(stream, callback)) {\n      return false;\n    }\n\n    stream.files.insertOne(filesDoc, { writeConcern: stream.writeConcern }).then(\n      () => {\n        stream.emit(GridFSBucketWriteStream.FINISH, filesDoc);\n        stream.emit(GridFSBucketWriteStream.CLOSE);\n      },\n      error => {\n        return __handleError(stream, error, callback);\n      }\n    );\n\n    return true;\n  }\n\n  return false;\n}\n\nasync function checkIndexes(stream: GridFSBucketWriteStream): Promise<void> {\n  const doc = await stream.files.findOne({}, { projection: { _id: 1 } });\n  if (doc != null) {\n    // If at least one document exists assume the collection has the required index\n    return;\n  }\n\n  const index = { filename: 1, uploadDate: 1 };\n\n  let indexes;\n  try {\n    indexes = await stream.files.listIndexes().toArray();\n  } catch (error) {\n    if (error instanceof MongoError && error.code === MONGODB_ERROR_CODES.NamespaceNotFound) {\n      indexes = [];\n    } else {\n      throw error;\n    }\n  }\n\n  const hasFileIndex = !!indexes.find(index => {\n    const keys = Object.keys(index.key);\n    if (keys.length === 2 && index.key.filename === 1 && index.key.uploadDate === 1) {\n      return true;\n    }\n    return false;\n  });\n\n  if (!hasFileIndex) {\n    await stream.files.createIndex(index, { background: false });\n  }\n\n  await checkChunksIndex(stream);\n}\n\nfunction createFilesDoc(\n  _id: ObjectId,\n  length: number,\n  chunkSize: number,\n  filename: string,\n  contentType?: string,\n  aliases?: string[],\n  metadata?: Document\n): GridFSFile {\n  const ret: GridFSFile = {\n    _id,\n    length,\n    chunkSize,\n    uploadDate: new Date(),\n    filename\n  };\n\n  if (contentType) {\n    ret.contentType = contentType;\n  }\n\n  if (aliases) {\n    ret.aliases = aliases;\n  }\n\n  if (metadata) {\n    ret.metadata = metadata;\n  }\n\n  return ret;\n}\n\nfunction doWrite(\n  stream: GridFSBucketWriteStream,\n  chunk: Buffer | string,\n  encoding?: BufferEncoding,\n  callback?: Callback<void>\n): boolean {\n  if (checkAborted(stream, callback)) {\n    return false;\n  }\n\n  const inputBuf = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk, encoding);\n\n  stream.length += inputBuf.length;\n\n  // Input is small enough to fit in our buffer\n  if (stream.pos + inputBuf.length < stream.chunkSizeBytes) {\n    inputBuf.copy(stream.bufToStore, stream.pos);\n    stream.pos += inputBuf.length;\n\n    callback && callback();\n\n    // Note that we reverse the typical semantics of write's return value\n    // to be compatible with node's `.pipe()` function.\n    // True means client can keep writing.\n    return true;\n  }\n\n  // Otherwise, buffer is too big for current chunk, so we need to flush\n  // to MongoDB.\n  let inputBufRemaining = inputBuf.length;\n  let spaceRemaining: number = stream.chunkSizeBytes - stream.pos;\n  let numToCopy = Math.min(spaceRemaining, inputBuf.length);\n  let outstandingRequests = 0;\n  while (inputBufRemaining > 0) {\n    const inputBufPos = inputBuf.length - inputBufRemaining;\n    inputBuf.copy(stream.bufToStore, stream.pos, inputBufPos, inputBufPos + numToCopy);\n    stream.pos += numToCopy;\n    spaceRemaining -= numToCopy;\n    let doc: GridFSChunk;\n    if (spaceRemaining === 0) {\n      doc = createChunkDoc(stream.id, stream.n, Buffer.from(stream.bufToStore));\n      ++stream.state.outstandingRequests;\n      ++outstandingRequests;\n\n      if (checkAborted(stream, callback)) {\n        return false;\n      }\n\n      stream.chunks.insertOne(doc, { writeConcern: stream.writeConcern }).then(\n        () => {\n          --stream.state.outstandingRequests;\n          --outstandingRequests;\n\n          if (!outstandingRequests) {\n            stream.emit('drain', doc);\n            callback && callback();\n            checkDone(stream);\n          }\n        },\n        error => {\n          return __handleError(stream, error);\n        }\n      );\n\n      spaceRemaining = stream.chunkSizeBytes;\n      stream.pos = 0;\n      ++stream.n;\n    }\n    inputBufRemaining -= numToCopy;\n    numToCopy = Math.min(spaceRemaining, inputBufRemaining);\n  }\n\n  // Note that we reverse the typical semantics of write's return value\n  // to be compatible with node's `.pipe()` function.\n  // False means the client should wait for the 'drain' event.\n  return false;\n}\n\nfunction waitForIndexes(\n  stream: GridFSBucketWriteStream,\n  callback: (res: boolean) => boolean\n): boolean {\n  if (stream.bucket.s.checkedIndexes) {\n    return callback(false);\n  }\n\n  stream.bucket.once('index', () => {\n    callback(true);\n  });\n\n  return true;\n}\n\nfunction writeRemnant(stream: GridFSBucketWriteStream, callback?: Callback): boolean {\n  // Buffer is empty, so don't bother to insert\n  if (stream.pos === 0) {\n    return checkDone(stream, callback);\n  }\n\n  ++stream.state.outstandingRequests;\n\n  // Create a new buffer to make sure the buffer isn't bigger than it needs\n  // to be.\n  const remnant = Buffer.alloc(stream.pos);\n  stream.bufToStore.copy(remnant, 0, 0, stream.pos);\n  const doc = createChunkDoc(stream.id, stream.n, remnant);\n\n  // If the stream was aborted, do not write remnant\n  if (checkAborted(stream, callback)) {\n    return false;\n  }\n\n  stream.chunks.insertOne(doc, { writeConcern: stream.writeConcern }).then(\n    () => {\n      --stream.state.outstandingRequests;\n      checkDone(stream);\n    },\n    error => {\n      return __handleError(stream, error);\n    }\n  );\n  return true;\n}\n\nfunction checkAborted(stream: GridFSBucketWriteStream, callback?: Callback<void>): boolean {\n  if (stream.state.aborted) {\n    if (typeof callback === 'function') {\n      // TODO(NODE-3485): Replace with MongoGridFSStreamClosedError\n      callback(new MongoAPIError('Stream has been aborted'));\n    }\n    return true;\n  }\n  return false;\n}\n"],"mappings":";;;;;;;;;;;;;;AAAA,IAAAA,QAAA,GAAAC,OAAA;AAGA,IAAAC,MAAA,GAAAD,OAAA;AAEA,IAAAE,OAAA,GAAAF,OAAA;AAGA,IAAAG,eAAA,GAAAH,OAAA;AA0BA;;;;;;AAAA,IAMaI,uBAAwB,0BAAAC,kBAAA;EAAAC,SAAA,CAAAF,uBAAA,EAAAC,kBAAA;EAAA,IAAAE,MAAA,GAAAC,YAAA,CAAAJ,uBAAA;EA+BnC;;;;;;EAMA,SAAAA,wBAAYK,MAAoB,EAAEC,QAAgB,EAAEC,OAAwC;IAAA,IAAAC,QAAA;IAAA,IAAAC,KAAA;IAAAC,eAAA,OAAAV,uBAAA;IAC1FS,KAAA,GAAAN,MAAA,CAAAQ,IAAA;IAEAJ,OAAO,IAAAC,QAAA,GAAGD,OAAO,cAAAC,QAAA,cAAAA,QAAA,GAAI,EAAE;IACvBC,KAAA,CAAKJ,MAAM,GAAGA,MAAM;IACpBI,KAAA,CAAKG,MAAM,GAAGP,MAAM,CAACQ,CAAC,CAACC,iBAAiB;IACxCL,KAAA,CAAKH,QAAQ,GAAGA,QAAQ;IACxBG,KAAA,CAAKM,KAAK,GAAGV,MAAM,CAACQ,CAAC,CAACG,gBAAgB;IACtCP,KAAA,CAAKF,OAAO,GAAGA,OAAO;IACtBE,KAAA,CAAKQ,YAAY,GAAGlB,eAAA,CAAAmB,YAAY,CAACC,WAAW,CAACZ,OAAO,CAAC,IAAIF,MAAM,CAACQ,CAAC,CAACN,OAAO,CAACU,YAAY;IACtF;IACAR,KAAA,CAAKW,IAAI,GAAG,KAAK;IAEjBX,KAAA,CAAKY,EAAE,GAAGd,OAAO,CAACc,EAAE,GAAGd,OAAO,CAACc,EAAE,GAAG,IAAIxB,MAAA,CAAAyB,QAAQ,EAAE;IAClD;IACAb,KAAA,CAAKc,cAAc,GAAGhB,OAAO,CAACgB,cAAc,IAAId,KAAA,CAAKJ,MAAM,CAACQ,CAAC,CAACN,OAAO,CAACgB,cAAc;IACpFd,KAAA,CAAKe,UAAU,GAAGC,MAAM,CAACC,KAAK,CAACjB,KAAA,CAAKc,cAAc,CAAC;IACnDd,KAAA,CAAKkB,MAAM,GAAG,CAAC;IACflB,KAAA,CAAKmB,CAAC,GAAG,CAAC;IACVnB,KAAA,CAAKoB,GAAG,GAAG,CAAC;IACZpB,KAAA,CAAKqB,KAAK,GAAG;MACXC,SAAS,EAAE,KAAK;MAChBC,mBAAmB,EAAE,CAAC;MACtBC,OAAO,EAAE,KAAK;MACdC,OAAO,EAAE;KACV;IAED,IAAI,CAACzB,KAAA,CAAKJ,MAAM,CAACQ,CAAC,CAACsB,sBAAsB,EAAE;MACzC1B,KAAA,CAAKJ,MAAM,CAACQ,CAAC,CAACsB,sBAAsB,GAAG,IAAI;MAE3CC,YAAY,CAAAC,sBAAA,CAAA5B,KAAA,CAAK,CAAC,CAAC6B,IAAI,CACrB,YAAK;QACH7B,KAAA,CAAKJ,MAAM,CAACQ,CAAC,CAAC0B,cAAc,GAAG,IAAI;QACnC9B,KAAA,CAAKJ,MAAM,CAACmC,IAAI,CAAC,OAAO,CAAC;MAC3B,CAAC,EACD;QAAA,OAAM,IAAI;MAAA,EACX;;IACF,OAAA/B,KAAA;EACH;EAACgC,YAAA,CAAAzC,uBAAA;IAAA0C,GAAA;IAAAC,KAAA,EAkBQ,SAAAC,MACPC,KAAsB,EACtBC,kBAAoD,EACpDC,QAAyB;MAAA,IAAAC,MAAA;MAEzB,IAAMC,QAAQ,GAAG,OAAOH,kBAAkB,KAAK,UAAU,GAAGI,SAAS,GAAGJ,kBAAkB;MAC1FC,QAAQ,GAAG,OAAOD,kBAAkB,KAAK,UAAU,GAAGA,kBAAkB,GAAGC,QAAQ;MACnF,OAAOI,cAAc,CAAC,IAAI,EAAE;QAAA,OAAMC,OAAO,CAACJ,MAAI,EAAEH,KAAK,EAAEI,QAAQ,EAAEF,QAAQ,CAAC;MAAA,EAAC;IAC7E;IAEA;;;;EAAA;IAAAL,GAAA;IAAAC,KAAA;MAAA,IAAAU,MAAA,GAAAC,iBAAA,eAAAC,mBAAA,GAAAC,IAAA,CAIA,SAAAC,QAAA;QAAA,OAAAF,mBAAA,GAAAG,IAAA,UAAAC,SAAAC,QAAA;UAAA,kBAAAA,QAAA,CAAAC,IAAA,GAAAD,QAAA,CAAAE,IAAA;YAAA;cAAA,KACM,IAAI,CAAChC,KAAK,CAACC,SAAS;gBAAA6B,QAAA,CAAAE,IAAA;gBAAA;cAAA;cAAA,MAEhB,IAAIhE,OAAA,CAAAiE,aAAa,CAAC,kDAAkD,CAAC;YAAA;cAAA,KAGzE,IAAI,CAACjC,KAAK,CAACI,OAAO;gBAAA0B,QAAA,CAAAE,IAAA;gBAAA;cAAA;cAAA,MAEd,IAAIhE,OAAA,CAAAiE,aAAa,CAAC,uCAAuC,CAAC;YAAA;cAGlE,IAAI,CAACjC,KAAK,CAACI,OAAO,GAAG,IAAI;cAAC0B,QAAA,CAAAE,IAAA;cAAA,OACpB,IAAI,CAAClD,MAAM,CAACoD,UAAU,CAAC;gBAAEC,QAAQ,EAAE,IAAI,CAAC5C;cAAE,CAAE,CAAC;YAAA;YAAA;cAAA,OAAAuC,QAAA,CAAAM,IAAA;UAAA;QAAA,GAAAT,OAAA;MAAA,CACpD;MAAA,SAAAU,MAAA;QAAA,OAAAd,MAAA,CAAAe,KAAA,OAAAC,SAAA;MAAA;MAAA,OAAAF,KAAA;IAAA;EAAA;IAAAzB,GAAA;IAAAC,KAAA,EAqBQ,SAAA2B,IACPC,eAAsD,EACtDzB,kBAAiE,EACjEC,QAAsC;MAAA,IAAAyB,MAAA;MAEtC,IAAM3B,KAAK,GAAG,OAAO0B,eAAe,KAAK,UAAU,GAAGrB,SAAS,GAAGqB,eAAe;MACjF,IAAMtB,QAAQ,GAAG,OAAOH,kBAAkB,KAAK,UAAU,GAAGI,SAAS,GAAGJ,kBAAkB;MAC1FC,QAAQ,GACN,OAAOwB,eAAe,KAAK,UAAU,GACjCA,eAAe,GACf,OAAOzB,kBAAkB,KAAK,UAAU,GACxCA,kBAAkB,GAClBC,QAAQ;MAEd,IAAI,IAAI,CAACjB,KAAK,CAACC,SAAS,IAAI0C,YAAY,CAAC,IAAI,EAAE1B,QAAQ,CAAC,EAAE,OAAO,IAAI;MAErE,IAAI,CAACjB,KAAK,CAACC,SAAS,GAAG,IAAI;MAE3B,IAAIgB,QAAQ,EAAE;QACZ,IAAI,CAAC2B,IAAI,CAAC1E,uBAAuB,CAAC2E,MAAM,EAAE,UAACC,MAAkB,EAAI;UAC/D,IAAI7B,QAAQ,EAAEA,QAAQ,CAACG,SAAS,EAAE0B,MAAM,CAAC;QAC3C,CAAC,CAAC;;MAGJ,IAAI,CAAC/B,KAAK,EAAE;QACVM,cAAc,CAAC,IAAI,EAAE;UAAA,OAAM,CAAC,CAAC0B,YAAY,CAACL,MAAI,CAAC;QAAA,EAAC;QAChD,OAAO,IAAI;;MAGb,IAAI,CAAC5B,KAAK,CAACC,KAAK,EAAEI,QAAQ,EAAE,YAAK;QAC/B4B,YAAY,CAACL,MAAI,CAAC;MACpB,CAAC,CAAC;MAEF,OAAO,IAAI;IACb;EAAC;EAAA,OAAAxE,uBAAA;AAAA,EA/K0CL,QAAA,CAAAmF,QAAQ;AAqBnD;AACgB9E,uBAAA,CAAA+E,KAAK,GAAG,OAAO;AAC/B;AACgB/E,uBAAA,CAAAgF,KAAK,GAAG,OAAO;AAC/B;;;;AAIgBhF,uBAAA,CAAA2E,MAAM,GAAG,QAAQ;AA7BtBM,OAAA,CAAAjF,uBAAA,GAAAA,uBAAA;AAkLb,SAASkF,aAAaA,CACpBC,MAA+B,EAC/BC,KAAe,EACfrC,QAAmB;EAEnB,IAAIoC,MAAM,CAACrD,KAAK,CAACG,OAAO,EAAE;IACxB;;EAEFkD,MAAM,CAACrD,KAAK,CAACG,OAAO,GAAG,IAAI;EAC3B,IAAIc,QAAQ,EAAE;IACZ,OAAOA,QAAQ,CAACqC,KAAK,CAAC;;EAExBD,MAAM,CAAC3C,IAAI,CAACxC,uBAAuB,CAACgF,KAAK,EAAEI,KAAK,CAAC;AACnD;AAEA,SAASC,cAAcA,CAACC,OAAiB,EAAE1D,CAAS,EAAE2D,IAAY;EAChE,OAAO;IACLC,GAAG,EAAE,IAAI3F,MAAA,CAAAyB,QAAQ,EAAE;IACnB2C,QAAQ,EAAEqB,OAAO;IACjB1D,CAAC,EAADA,CAAC;IACD2D,IAAI,EAAJA;GACD;AACH;AAAC,SAEcE,gBAAgBA,CAAAC,EAAA;EAAA,OAAAC,iBAAA,CAAAvB,KAAA,OAAAC,SAAA;AAAA;AAAA,SAAAsB,kBAAA;EAAAA,iBAAA,GAAArC,iBAAA,eAAAC,mBAAA,GAAAC,IAAA,CAA/B,SAAAoC,SAAgCT,MAA+B;IAAA,IAAAU,KAAA,EAAAC,OAAA,EAAAC,cAAA;IAAA,OAAAxC,mBAAA,GAAAG,IAAA,UAAAsC,UAAAC,SAAA;MAAA,kBAAAA,SAAA,CAAApC,IAAA,GAAAoC,SAAA,CAAAnC,IAAA;QAAA;UACvD+B,KAAK,GAAG;YAAE5B,QAAQ,EAAE,CAAC;YAAErC,CAAC,EAAE;UAAC,CAAE;UAAAqE,SAAA,CAAApC,IAAA;UAAAoC,SAAA,CAAAnC,IAAA;UAAA,OAIjBqB,MAAM,CAACvE,MAAM,CAACsF,WAAW,EAAE,CAACC,OAAO,EAAE;QAAA;UAArDL,OAAO,GAAAG,SAAA,CAAAG,IAAA;UAAAH,SAAA,CAAAnC,IAAA;UAAA;QAAA;UAAAmC,SAAA,CAAApC,IAAA;UAAAoC,SAAA,CAAAI,EAAA,GAAAJ,SAAA;UAAA,MAEHA,SAAA,CAAAI,EAAA,YAAiBvG,OAAA,CAAAwG,UAAU,IAAIL,SAAA,CAAAI,EAAA,CAAME,IAAI,KAAKzG,OAAA,CAAA0G,mBAAmB,CAACC,iBAAiB;YAAAR,SAAA,CAAAnC,IAAA;YAAA;UAAA;UACrFgC,OAAO,GAAG,EAAE;UAACG,SAAA,CAAAnC,IAAA;UAAA;QAAA;UAAA,MAAAmC,SAAA,CAAAI,EAAA;QAAA;UAMXN,cAAc,GAAG,CAAC,CAACD,OAAO,CAACY,IAAI,CAAC,UAAAb,KAAK,EAAG;YAC5C,IAAMc,IAAI,GAAGC,MAAM,CAACD,IAAI,CAACd,KAAK,CAACnD,GAAG,CAAC;YACnC,IAAIiE,IAAI,CAAChF,MAAM,KAAK,CAAC,IAAIkE,KAAK,CAACnD,GAAG,CAACuB,QAAQ,KAAK,CAAC,IAAI4B,KAAK,CAACnD,GAAG,CAACd,CAAC,KAAK,CAAC,EAAE;cACtE,OAAO,IAAI;;YAEb,OAAO,KAAK;UACd,CAAC,CAAC;UAAA,IAEGmE,cAAc;YAAAE,SAAA,CAAAnC,IAAA;YAAA;UAAA;UAAAmC,SAAA,CAAAnC,IAAA;UAAA,OACXqB,MAAM,CAACvE,MAAM,CAACiG,WAAW,CAAChB,KAAK,EAAAiB,aAAA,CAAAA,aAAA,KAChC3B,MAAM,CAAClE,YAAY;YACtB8F,UAAU,EAAE,IAAI;YAChBC,MAAM,EAAE;UAAI,EACb,CAAC;QAAA;QAAA;UAAA,OAAAf,SAAA,CAAA/B,IAAA;MAAA;IAAA,GAAA0B,QAAA;EAAA,CAEL;EAAA,OAAAD,iBAAA,CAAAvB,KAAA,OAAAC,SAAA;AAAA;AAED,SAAS4C,SAASA,CAAC9B,MAA+B,EAAEpC,QAAmB;EACrE,IAAIoC,MAAM,CAAC/D,IAAI,EAAE,OAAO,IAAI;EAC5B,IAAI+D,MAAM,CAACrD,KAAK,CAACC,SAAS,IAAIoD,MAAM,CAACrD,KAAK,CAACE,mBAAmB,KAAK,CAAC,IAAI,CAACmD,MAAM,CAACrD,KAAK,CAACG,OAAO,EAAE;IAC7F;IACAkD,MAAM,CAAC/D,IAAI,GAAG,IAAI;IAClB;IACA,IAAM8F,QAAQ,GAAGC,cAAc,CAC7BhC,MAAM,CAAC9D,EAAE,EACT8D,MAAM,CAACxD,MAAM,EACbwD,MAAM,CAAC5D,cAAc,EACrB4D,MAAM,CAAC7E,QAAQ,EACf6E,MAAM,CAAC5E,OAAO,CAAC6G,WAAW,EAC1BjC,MAAM,CAAC5E,OAAO,CAAC8G,OAAO,EACtBlC,MAAM,CAAC5E,OAAO,CAAC+G,QAAQ,CACxB;IAED,IAAI7C,YAAY,CAACU,MAAM,EAAEpC,QAAQ,CAAC,EAAE;MAClC,OAAO,KAAK;;IAGdoC,MAAM,CAACpE,KAAK,CAACwG,SAAS,CAACL,QAAQ,EAAE;MAAEjG,YAAY,EAAEkE,MAAM,CAAClE;IAAY,CAAE,CAAC,CAACqB,IAAI,CAC1E,YAAK;MACH6C,MAAM,CAAC3C,IAAI,CAACxC,uBAAuB,CAAC2E,MAAM,EAAEuC,QAAQ,CAAC;MACrD/B,MAAM,CAAC3C,IAAI,CAACxC,uBAAuB,CAAC+E,KAAK,CAAC;IAC5C,CAAC,EACD,UAAAK,KAAK,EAAG;MACN,OAAOF,aAAa,CAACC,MAAM,EAAEC,KAAK,EAAErC,QAAQ,CAAC;IAC/C,CAAC,CACF;IAED,OAAO,IAAI;;EAGb,OAAO,KAAK;AACd;AAAC,SAEcX,YAAYA,CAAAoF,GAAA;EAAA,OAAAC,aAAA,CAAArD,KAAA,OAAAC,SAAA;AAAA;AAAA,SAAAoD,cAAA;EAAAA,aAAA,GAAAnE,iBAAA,eAAAC,mBAAA,GAAAC,IAAA,CAA3B,SAAAkE,SAA4BvC,MAA+B;IAAA,IAAAwC,GAAA,EAAA9B,KAAA,EAAAC,OAAA,EAAA8B,YAAA;IAAA,OAAArE,mBAAA,GAAAG,IAAA,UAAAmE,UAAAC,SAAA;MAAA,kBAAAA,SAAA,CAAAjE,IAAA,GAAAiE,SAAA,CAAAhE,IAAA;QAAA;UAAAgE,SAAA,CAAAhE,IAAA;UAAA,OACvCqB,MAAM,CAACpE,KAAK,CAACgH,OAAO,CAAC,EAAE,EAAE;YAAEC,UAAU,EAAE;cAAExC,GAAG,EAAE;YAAC;UAAE,CAAE,CAAC;QAAA;UAAhEmC,GAAG,GAAAG,SAAA,CAAA1B,IAAA;UAAA,MACLuB,GAAG,IAAI,IAAI;YAAAG,SAAA,CAAAhE,IAAA;YAAA;UAAA;UAAA,OAAAgE,SAAA,CAAAG,MAAA;QAAA;UAKTpC,KAAK,GAAG;YAAEvF,QAAQ,EAAE,CAAC;YAAE4H,UAAU,EAAE;UAAC,CAAE;UAAAJ,SAAA,CAAAjE,IAAA;UAAAiE,SAAA,CAAAhE,IAAA;UAAA,OAI1BqB,MAAM,CAACpE,KAAK,CAACmF,WAAW,EAAE,CAACC,OAAO,EAAE;QAAA;UAApDL,OAAO,GAAAgC,SAAA,CAAA1B,IAAA;UAAA0B,SAAA,CAAAhE,IAAA;UAAA;QAAA;UAAAgE,SAAA,CAAAjE,IAAA;UAAAiE,SAAA,CAAAzB,EAAA,GAAAyB,SAAA;UAAA,MAEHA,SAAA,CAAAzB,EAAA,YAAiBvG,OAAA,CAAAwG,UAAU,IAAIwB,SAAA,CAAAzB,EAAA,CAAME,IAAI,KAAKzG,OAAA,CAAA0G,mBAAmB,CAACC,iBAAiB;YAAAqB,SAAA,CAAAhE,IAAA;YAAA;UAAA;UACrFgC,OAAO,GAAG,EAAE;UAACgC,SAAA,CAAAhE,IAAA;UAAA;QAAA;UAAA,MAAAgE,SAAA,CAAAzB,EAAA;QAAA;UAMXuB,YAAY,GAAG,CAAC,CAAC9B,OAAO,CAACY,IAAI,CAAC,UAAAb,KAAK,EAAG;YAC1C,IAAMc,IAAI,GAAGC,MAAM,CAACD,IAAI,CAACd,KAAK,CAACnD,GAAG,CAAC;YACnC,IAAIiE,IAAI,CAAChF,MAAM,KAAK,CAAC,IAAIkE,KAAK,CAACnD,GAAG,CAACpC,QAAQ,KAAK,CAAC,IAAIuF,KAAK,CAACnD,GAAG,CAACwF,UAAU,KAAK,CAAC,EAAE;cAC/E,OAAO,IAAI;;YAEb,OAAO,KAAK;UACd,CAAC,CAAC;UAAA,IAEGN,YAAY;YAAAE,SAAA,CAAAhE,IAAA;YAAA;UAAA;UAAAgE,SAAA,CAAAhE,IAAA;UAAA,OACTqB,MAAM,CAACpE,KAAK,CAAC8F,WAAW,CAAChB,KAAK,EAAE;YAAEkB,UAAU,EAAE;UAAK,CAAE,CAAC;QAAA;UAAAe,SAAA,CAAAhE,IAAA;UAAA,OAGxD2B,gBAAgB,CAACN,MAAM,CAAC;QAAA;QAAA;UAAA,OAAA2C,SAAA,CAAA5D,IAAA;MAAA;IAAA,GAAAwD,QAAA;EAAA,CAC/B;EAAA,OAAAD,aAAA,CAAArD,KAAA,OAAAC,SAAA;AAAA;AAED,SAAS8C,cAAcA,CACrB3B,GAAa,EACb7D,MAAc,EACdwG,SAAiB,EACjB7H,QAAgB,EAChB8G,WAAoB,EACpBC,OAAkB,EAClBC,QAAmB;EAEnB,IAAMc,GAAG,GAAe;IACtB5C,GAAG,EAAHA,GAAG;IACH7D,MAAM,EAANA,MAAM;IACNwG,SAAS,EAATA,SAAS;IACTD,UAAU,EAAE,IAAIG,IAAI,EAAE;IACtB/H,QAAQ,EAARA;GACD;EAED,IAAI8G,WAAW,EAAE;IACfgB,GAAG,CAAChB,WAAW,GAAGA,WAAW;;EAG/B,IAAIC,OAAO,EAAE;IACXe,GAAG,CAACf,OAAO,GAAGA,OAAO;;EAGvB,IAAIC,QAAQ,EAAE;IACZc,GAAG,CAACd,QAAQ,GAAGA,QAAQ;;EAGzB,OAAOc,GAAG;AACZ;AAEA,SAAShF,OAAOA,CACd+B,MAA+B,EAC/BtC,KAAsB,EACtBI,QAAyB,EACzBF,QAAyB;EAEzB,IAAI0B,YAAY,CAACU,MAAM,EAAEpC,QAAQ,CAAC,EAAE;IAClC,OAAO,KAAK;;EAGd,IAAMuF,QAAQ,GAAG7G,MAAM,CAAC8G,QAAQ,CAAC1F,KAAK,CAAC,GAAGA,KAAK,GAAGpB,MAAM,CAAC+G,IAAI,CAAC3F,KAAK,EAAEI,QAAQ,CAAC;EAE9EkC,MAAM,CAACxD,MAAM,IAAI2G,QAAQ,CAAC3G,MAAM;EAEhC;EACA,IAAIwD,MAAM,CAACtD,GAAG,GAAGyG,QAAQ,CAAC3G,MAAM,GAAGwD,MAAM,CAAC5D,cAAc,EAAE;IACxD+G,QAAQ,CAACG,IAAI,CAACtD,MAAM,CAAC3D,UAAU,EAAE2D,MAAM,CAACtD,GAAG,CAAC;IAC5CsD,MAAM,CAACtD,GAAG,IAAIyG,QAAQ,CAAC3G,MAAM;IAE7BoB,QAAQ,IAAIA,QAAQ,EAAE;IAEtB;IACA;IACA;IACA,OAAO,IAAI;;EAGb;EACA;EACA,IAAI2F,iBAAiB,GAAGJ,QAAQ,CAAC3G,MAAM;EACvC,IAAIgH,cAAc,GAAWxD,MAAM,CAAC5D,cAAc,GAAG4D,MAAM,CAACtD,GAAG;EAC/D,IAAI+G,SAAS,GAAGC,IAAI,CAACC,GAAG,CAACH,cAAc,EAAEL,QAAQ,CAAC3G,MAAM,CAAC;EACzD,IAAIK,mBAAmB,GAAG,CAAC;EAAC,IAAA+G,KAAA,YAAAA,MAAA,EACE;IAC5B,IAAMC,WAAW,GAAGV,QAAQ,CAAC3G,MAAM,GAAG+G,iBAAiB;IACvDJ,QAAQ,CAACG,IAAI,CAACtD,MAAM,CAAC3D,UAAU,EAAE2D,MAAM,CAACtD,GAAG,EAAEmH,WAAW,EAAEA,WAAW,GAAGJ,SAAS,CAAC;IAClFzD,MAAM,CAACtD,GAAG,IAAI+G,SAAS;IACvBD,cAAc,IAAIC,SAAS;IAC3B,IAAIjB,GAAgB;IACpB,IAAIgB,cAAc,KAAK,CAAC,EAAE;MACxBhB,GAAG,GAAGtC,cAAc,CAACF,MAAM,CAAC9D,EAAE,EAAE8D,MAAM,CAACvD,CAAC,EAAEH,MAAM,CAAC+G,IAAI,CAACrD,MAAM,CAAC3D,UAAU,CAAC,CAAC;MACzE,EAAE2D,MAAM,CAACrD,KAAK,CAACE,mBAAmB;MAClC,EAAEA,mBAAmB;MAErB,IAAIyC,YAAY,CAACU,MAAM,EAAEpC,QAAQ,CAAC,EAAE;QAAA;UAAAkG,CAAA,EAC3B;QAAK;;MAGd9D,MAAM,CAACvE,MAAM,CAAC2G,SAAS,CAACI,GAAG,EAAE;QAAE1G,YAAY,EAAEkE,MAAM,CAAClE;MAAY,CAAE,CAAC,CAACqB,IAAI,CACtE,YAAK;QACH,EAAE6C,MAAM,CAACrD,KAAK,CAACE,mBAAmB;QAClC,EAAEA,mBAAmB;QAErB,IAAI,CAACA,mBAAmB,EAAE;UACxBmD,MAAM,CAAC3C,IAAI,CAAC,OAAO,EAAEmF,GAAG,CAAC;UACzB5E,QAAQ,IAAIA,QAAQ,EAAE;UACtBkE,SAAS,CAAC9B,MAAM,CAAC;;MAErB,CAAC,EACD,UAAAC,KAAK,EAAG;QACN,OAAOF,aAAa,CAACC,MAAM,EAAEC,KAAK,CAAC;MACrC,CAAC,CACF;MAEDuD,cAAc,GAAGxD,MAAM,CAAC5D,cAAc;MACtC4D,MAAM,CAACtD,GAAG,GAAG,CAAC;MACd,EAAEsD,MAAM,CAACvD,CAAC;;IAEZ8G,iBAAiB,IAAIE,SAAS;IAC9BA,SAAS,GAAGC,IAAI,CAACC,GAAG,CAACH,cAAc,EAAED,iBAAiB,CAAC;GACxD;EArCD,OAAOA,iBAAiB,GAAG,CAAC;IAAA,IAAAQ,IAAA,GAAAH,KAAA;IAAA,WAAAG,IAAA,sBAAAA,IAAA,CAAAD,CAAA;EAAA;EAuC5B;EACA;EACA;EACA,OAAO,KAAK;AACd;AAEA,SAAS9F,cAAcA,CACrBgC,MAA+B,EAC/BpC,QAAmC;EAEnC,IAAIoC,MAAM,CAAC9E,MAAM,CAACQ,CAAC,CAAC0B,cAAc,EAAE;IAClC,OAAOQ,QAAQ,CAAC,KAAK,CAAC;;EAGxBoC,MAAM,CAAC9E,MAAM,CAACqE,IAAI,CAAC,OAAO,EAAE,YAAK;IAC/B3B,QAAQ,CAAC,IAAI,CAAC;EAChB,CAAC,CAAC;EAEF,OAAO,IAAI;AACb;AAEA,SAAS8B,YAAYA,CAACM,MAA+B,EAAEpC,QAAmB;EACxE;EACA,IAAIoC,MAAM,CAACtD,GAAG,KAAK,CAAC,EAAE;IACpB,OAAOoF,SAAS,CAAC9B,MAAM,EAAEpC,QAAQ,CAAC;;EAGpC,EAAEoC,MAAM,CAACrD,KAAK,CAACE,mBAAmB;EAElC;EACA;EACA,IAAMmH,OAAO,GAAG1H,MAAM,CAACC,KAAK,CAACyD,MAAM,CAACtD,GAAG,CAAC;EACxCsD,MAAM,CAAC3D,UAAU,CAACiH,IAAI,CAACU,OAAO,EAAE,CAAC,EAAE,CAAC,EAAEhE,MAAM,CAACtD,GAAG,CAAC;EACjD,IAAM8F,GAAG,GAAGtC,cAAc,CAACF,MAAM,CAAC9D,EAAE,EAAE8D,MAAM,CAACvD,CAAC,EAAEuH,OAAO,CAAC;EAExD;EACA,IAAI1E,YAAY,CAACU,MAAM,EAAEpC,QAAQ,CAAC,EAAE;IAClC,OAAO,KAAK;;EAGdoC,MAAM,CAACvE,MAAM,CAAC2G,SAAS,CAACI,GAAG,EAAE;IAAE1G,YAAY,EAAEkE,MAAM,CAAClE;EAAY,CAAE,CAAC,CAACqB,IAAI,CACtE,YAAK;IACH,EAAE6C,MAAM,CAACrD,KAAK,CAACE,mBAAmB;IAClCiF,SAAS,CAAC9B,MAAM,CAAC;EACnB,CAAC,EACD,UAAAC,KAAK,EAAG;IACN,OAAOF,aAAa,CAACC,MAAM,EAAEC,KAAK,CAAC;EACrC,CAAC,CACF;EACD,OAAO,IAAI;AACb;AAEA,SAASX,YAAYA,CAACU,MAA+B,EAAEpC,QAAyB;EAC9E,IAAIoC,MAAM,CAACrD,KAAK,CAACI,OAAO,EAAE;IACxB,IAAI,OAAOa,QAAQ,KAAK,UAAU,EAAE;MAClC;MACAA,QAAQ,CAAC,IAAIjD,OAAA,CAAAiE,aAAa,CAAC,yBAAyB,CAAC,CAAC;;IAExD,OAAO,IAAI;;EAEb,OAAO,KAAK;AACd"},"metadata":{},"sourceType":"script","externalDependencies":[]}